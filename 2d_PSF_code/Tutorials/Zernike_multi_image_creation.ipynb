{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "977bedaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Feb 20 2023\n",
    "@author: Neven Caplar\n",
    "@contact: ncaplar@princeton.edu / ncaplar@uw.edu\n",
    "\n",
    "These comments are theoretically the only ones you need to read to run the notebook\n",
    "\n",
    "1. Specify the directory in which you want to run the analysis below (PSF_DIRECTORY)\n",
    "2. Name and place the data in DATA_FOLDER. The data is avaliable at https://github.com/nevencaplar/PFS_Work_In_Progress/tree/master/CutsForTigerMay2\n",
    "3. TESTING_FOLDER will be filled during the run with images from the analysis analysis\n",
    "\n",
    "4. (OPTIONAL)Next cell contains some extensions that I use that make life much easier when using jupyter notebook \n",
    "    Without them this notebook becomes reallllly huge and hard to deal with\n",
    "    These can be downloaded from https://github.com/ipython-contrib/jupyter_contrib_nbextensions\n",
    "\n",
    "\"\"\"\n",
    "############################################################\n",
    "# name your directory where you want to have files!\n",
    "PSF_DIRECTORY='/tigress/ncaplar/PFS/'\n",
    "# place cutouts in this folder - name as you wish\n",
    "DATA_FOLDER=PSF_DIRECTORY+'TigerAnalysis/CutsForTigerMay2/'\n",
    "############################################################\n",
    "    \n",
    "\n",
    "TESTING_FOLDER=PSF_DIRECTORY+'Testing/'\n",
    "TESTING_PUPIL_IMAGES_FOLDER=TESTING_FOLDER+'Pupil_Images/'\n",
    "TESTING_WAVEFRONT_IMAGES_FOLDER=TESTING_FOLDER+'Wavefront_Images/'\n",
    "TESTING_FINAL_IMAGES_FOLDER=TESTING_FOLDER+'Final_Images/'\n",
    "import os\n",
    "\n",
    "for i in [PSF_DIRECTORY,DATA_FOLDER,TESTING_PUPIL_IMAGES_FOLDER,TESTING_WAVEFRONT_IMAGES_FOLDER,TESTING_FINAL_IMAGES_FOLDER]:\n",
    "    if not os.path.exists(i):\n",
    "        os.makedirs(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "253bd79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_210141/2877485811.py:2: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zernike_Module.__version__: 0.52\n",
      "Zernike_Analysis_Module.__version__: 0.26l\n",
      "1.20.3\n",
      "1.8.1\n",
      "1.4.2\n"
     ]
    }
   ],
   "source": [
    "# make notebook nice and wide to fill the entire screen\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import Zernike_Module\n",
    "import Zernike_Analysis_Module\n",
    "from Zernike_Module import *\n",
    "from Residual_1D_module import * \n",
    "from Zernike_Analysis_Module import *\n",
    "\n",
    "print('Zernike_Module.__version__: '+str(Zernike_Module.__version__))\n",
    "print('Zernike_Analysis_Module.__version__: '+str(Zernike_Analysis_Module.__version__))\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "import pandas as pd\n",
    "import io\n",
    "import math\n",
    "import pickle\n",
    "import glob\n",
    "import time\n",
    "from shutil import copy\n",
    "\n",
    "print(np.__version__)\n",
    "print(scipy.__version__)\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "771dcc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First import all of the dataframes contaning information about the spots\n",
    "\n",
    "import glob\n",
    "\n",
    "#finalAr_wrong_secondary=np.load(\"/tigress/ncaplar/ReducedData/Data_May_21_2021/Dataframes/finalAr_Jul2021_wrong_secondary\",allow_pickle=True)\n",
    "finalAr=np.load(\"/tigress/ncaplar/ReducedData/Data_May_25_2021/Dataframes/finalAr_Jul2021\",allow_pickle=True)\n",
    "finalNe=np.load(\"/tigress/ncaplar/ReducedData/Data_May_25_2021/Dataframes/finalNe_Jul2021\",allow_pickle=True)\n",
    "finalKr=np.load(\"/tigress/ncaplar/ReducedData/Data_May_25_2021/Dataframes/finalKr_Jul2021\",allow_pickle=True)\n",
    "\n",
    "def remove(string): \n",
    "    return string.replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1725ddf3",
   "metadata": {},
   "source": [
    "We will create scripts for analyzing all of the spots. We have to create scripts for 10-fiber and 21-fiber configuration separatly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e74a748d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Argon spots: 80\n",
      "Number of Neon spots: 40\n",
      "Number of Krypton spots: 10\n",
      "Argon index to be analyzed: [  1   3   5   6   7   8   9  11  13  15  17  18  19  20  21  23  25  27\n",
      "  29  30  31  32  33  35  37  39  41  42  43  44  45  47  49  51  53  54\n",
      "  55  56  57  59  61  63  65  66  67  68  69  71  73  75  77  78  79  80\n",
      "  81  83  85  87  89  90  91  92  93  95  97  99 101 102 103 104 105 107\n",
      " 109 111 113 114 115 116 117 119]\n",
      "Neon index to be analyzed: [ 2  5  6  7 11 14 15 16 20 23 24 25 29 32 33 34 38 41 42 43 47 50 51 52\n",
      " 56 59 60 61 65 68 69 70 74 77 78 79 83 86 87 88]\n",
      "Krypton index to be analyzed: [ 3  7 11 15 19 23 27 31 35 39]\n"
     ]
    }
   ],
   "source": [
    "# Select the spots that are well separate (close = 1) and are in 10-fiber configuration\n",
    "# Id smaller than 120 for Argon, 90 for neon, 40 for Krypton\n",
    "\n",
    "list_of_Ar_to_analyze=(finalAr[finalAr['close']=='1'].index)[(finalAr[finalAr['close']=='1'].index)<120]\n",
    "list_of_Ne_to_analyze=finalNe[finalNe['close']=='1'].index [(finalNe[finalNe['close']=='1'].index)<90]\n",
    "list_of_Kr_to_analyze=finalKr[finalKr['close']==1].index [(finalKr[finalKr['close']==1].index)<40]\n",
    "\n",
    "#print(len(list_of_HgAr_to_analyze))\n",
    "print('Number of Argon spots: ' + str(len(list_of_Ar_to_analyze)))\n",
    "print('Number of Neon spots: ' + str(len(list_of_Ne_to_analyze)))\n",
    "print('Number of Krypton spots: ' + str(len(list_of_Kr_to_analyze)))\n",
    "\n",
    "print('Argon index to be analyzed: '+str(list_of_Ar_to_analyze.values))\n",
    "print('Neon index to be analyzed: '+str(list_of_Ne_to_analyze.values))\n",
    "print('Krypton index to be analyzed: '+str(list_of_Kr_to_analyze.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385f9664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the date on which you are running this analysis\n",
    "# this date will propagate through the names everywhere\n",
    "\n",
    "date='Nov2221'\n",
    "\n",
    "# go through all 10 fibers\n",
    "for f in range(10):\n",
    "    # select a single spot\n",
    "    # this will only be used to select the values for offsets when there are \n",
    "    # multiple spots - so in this version of the code this is basically irellevant\n",
    "\n",
    "    # Again, because we are only analyzing spots that are well separated \n",
    "    # this is always going to False\n",
    "    single_spot=list_of_Ar_to_analyze[f*8:(f+1)*8][0]\n",
    "    if str(finalAr.loc[single_spot]['close'])=='0' or str(finalAr.loc[single_spot]['close'])=='0.5':\n",
    "        double_source=True\n",
    "    else:\n",
    "        double_source=False    \n",
    "    \n",
    "    # This a list of all of spots in a single fiber that we analyze\n",
    "    single_string=\" \".join(list_of_Ar_to_analyze[f*8:(f+1)*8].astype(str))\n",
    "    # Create a script file\n",
    "    file = open('/home/ncaplar/Scripts/D_Ar_1_'+str(f)+date+'.sh','w') \n",
    "    file.write(\"#!/bin/bash \\n\")\n",
    "    # how many nodes are we using when using tiger\n",
    "    # it has to be 1; is using more than 1 we have to use mpirun, or more advancded methods\n",
    "    file.write(\"#SBATCH --nodes=1 # node count \\n\")\n",
    "    # how many cored in a node\n",
    "    file.write(\"#SBATCH --ntasks-per-node=28 \\n\") \n",
    "    # limit on the time that the process will run\n",
    "    file.write(\"#SBATCH --time 23:55:59 \\n\")\n",
    "    file.write(\"#SBATCH --mail-type=begin  \\n\")\n",
    "    file.write(\"#SBATCH --mail-type=end   \\n\") \n",
    "    file.write(\"#SBATCH --mail-user=ncaplar@princeton.edu \\n\") \n",
    "\n",
    "    # Before running the PFS enviroment needs to be setup - one can do that before submitting the script\n",
    "    # or it can be specified here \n",
    "    # source /tigress/HSC/PFS/stack/current/loadLSST.bash; source scl_source enable devtoolset-6; setup pfs_pipe2d; setup galsim; setup matplotlib; setup display_matplotlib;\n",
    "    \n",
    "    # We run Zernike_parameter_estimation\n",
    "    # We specify observations on which the analyis is being run with -obs \n",
    "    #    In this case we specify 34341 34389 34438 which correspodns to one observation at one side of focus (-4 mm), focus (0 mm), and other side of focus (4mm)\n",
    "    # Specify the number of steps that algorithm will take with nsteps. This is usually as high as you can make it; I usually used 30, 40, or 50 steps\n",
    "    # Eps specify how many workers will the process spawn - the options are specified in Zernike_parameter_estimation\n",
    "    # Dataset - make sure that if analyzing 10 fiber configuration that you specify the datasets that correspond to 10 fibers\n",
    "    # Arc - which lamp are we going to analyze\n",
    "    # double_sources and double_sources_positions_ratios are populated automatically and should be False and 0,0\n",
    "    # twentytwo_or_extra: specify how many Zernike parameters will you use (22 or more, i.e., extra)\n",
    "    # date_of_input - what is the name of the dataframe from which you will supply input \n",
    "    # direct_or_interpolation - specify direct\n",
    "    # date_of_output - name of the output specified earlier\n",
    "    # analysis_type - it can be defocus or focus. Specify ``defocus'' here. Focus was old mode in which we did not modify any of the Zernike parameters\n",
    "    # or illumination parameters.\n",
    "    file.write(\"python /home/ncaplar/Code/Zernike_parameter_estimation.py -obs 34341 34389 34437 -spot \"+str(single_string)+\\\n",
    "               \" -nsteps 31 -eps 8 -dataset 6 -arc Ar -double_sources \"+str(double_source)+\\\n",
    "               \" -double_sources_positions_ratios \"+remove(str(list(finalAr.loc[single_spot][['second_offset','second_ratio']].values)))+\\\n",
    "               \" -twentytwo_or_extra 56 -date_of_input Sep0521 -direct_or_interpolation direct -date_of_output \"+date+\" -analysis_type defocus \\n\")\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dec692d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How would we do this for 21 fiber configuration?\n",
    "# We follow the same procedure as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa235960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168\n",
      "84\n",
      "21\n",
      "Int64Index([121, 123, 125, 126, 127, 128, 129, 131, 133, 135,\n",
      "            ...\n",
      "            357, 359, 361, 363, 365, 366, 367, 368, 369, 371],\n",
      "           dtype='int64', length=168)\n",
      "Int64Index([ 92,  95,  96,  97, 101, 104, 105, 106, 110, 113, 114, 115, 119,\n",
      "            122, 123, 124, 128, 131, 132, 133, 137, 140, 141, 142, 146, 149,\n",
      "            150, 151, 155, 158, 159, 160, 164, 167, 168, 169, 173, 176, 177,\n",
      "            178, 182, 185, 186, 187, 191, 194, 195, 196, 200, 203, 204, 205,\n",
      "            209, 212, 213, 214, 218, 221, 222, 223, 227, 230, 231, 232, 236,\n",
      "            239, 240, 241, 245, 248, 249, 250, 254, 257, 258, 259, 263, 266,\n",
      "            267, 268, 272, 275, 276, 277],\n",
      "           dtype='int64')\n",
      "Int64Index([ 43,  47,  51,  55,  59,  63,  67,  71,  75,  79,  83,  87,  91,\n",
      "             95,  99, 103, 107, 111, 115, 119, 123],\n",
      "           dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "# Find all of the well isolated spots in 21 fiber configuration\n",
    "list_of_Ar_to_analyze=(finalAr[finalAr['close']=='1'].index)[(finalAr[finalAr['close']=='1'].index)>120]\n",
    "list_of_Ne_to_analyze=finalNe[finalNe['close']=='1'].index [(finalNe[finalNe['close']=='1'].index)>90]\n",
    "list_of_Kr_to_analyze=finalKr[finalKr['close']==1].index [(finalKr[finalKr['close']==1].index)>40]\n",
    "\n",
    "#print(len(list_of_HgAr_to_analyze))\n",
    "print(len(list_of_Ar_to_analyze))\n",
    "print(len(list_of_Ne_to_analyze))\n",
    "print(len(list_of_Kr_to_analyze))\n",
    "\n",
    "print(list_of_Ar_to_analyze)\n",
    "print(list_of_Ne_to_analyze)\n",
    "print(list_of_Kr_to_analyze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1907270",
   "metadata": {},
   "outputs": [],
   "source": [
    "date='Nov2221'\n",
    "\n",
    "# note the difference here in the number of fibers\n",
    "# I specify here all 21 fibers, even though I know that 2 fibers will fail immedietly\n",
    "# These prcoess will just die quickly so there is no significant overhead\n",
    "for f in range(21):\n",
    "    single_spot=list_of_Ar_to_analyze[f*8:(f+1)*8][0]\n",
    "    if str(finalAr.loc[single_spot]['close'])=='0' or str(finalAr.loc[single_spot]['close'])=='0.5':\n",
    "        double_source=True\n",
    "    else:\n",
    "        double_source=False    \n",
    "        \n",
    "    single_string=\" \".join(list_of_Ar_to_analyze[f*8:(f+1)*8].astype(str))\n",
    "    # I name these scripts differently - `D_Ar_2` instead of `D_Ar_1` above\n",
    "    file = open('/home/ncaplar/Scripts/D_Ar_2_'+str(f)+date+'.sh','w') \n",
    "    file.write(\"#!/bin/bash \\n\")\n",
    "    file.write(\"#SBATCH --nodes=1 # node count \\n\")\n",
    "    file.write(\"#SBATCH --ntasks-per-node=28 \\n\") \n",
    "    file.write(\"#SBATCH --time 23:55:59 \\n\")\n",
    "    file.write(\"#SBATCH --mail-type=begin  \\n\")\n",
    "    file.write(\"#SBATCH --mail-type=end   \\n\") \n",
    "    file.write(\"#SBATCH --mail-user=ncaplar@princeton.edu \\n\") \n",
    "\n",
    "    file.write(\"\\n\")\n",
    "    file.write(\"#1. Observation (e.g., 8567) \\n\") \n",
    "    file.write(\"#2. Threads \\n\") \n",
    "    file.write(\"#3. Steps \\n\") \n",
    "    file.write(\"\\n\")\n",
    "    \n",
    "    # Note the difference in 1. observations specified and 2. dataset variable!\n",
    "    file.write(\"python /home/ncaplar/Code/Zernike_parameter_estimation.py -obs 51485 51581 51677 -spot \"+str(single_string)+\\\n",
    "               \" -nsteps 31 -eps 8 -dataset 8 -arc Ar -double_sources \"+str(double_source)+\\\n",
    "               \" -double_sources_positions_ratios \"+remove(str(list(finalAr.loc[single_spot][['second_offset','second_ratio']].values)))+\\\n",
    "               \" -twentytwo_or_extra 56 -date_of_input Sep0521 -direct_or_interpolation direct -date_of_output \"+date+\" -analysis_type defocus \\n\")\n",
    "    file.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "991cb990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to submit such a script on tiger and or Hilo machine\n",
    "# one would then run sbatch e.g., `/home/ncaplar/Scripts/D_Kr_2_15Nov2221.sh` where `/home/ncaplar/Scripts/` is the location where the script have been stored\n",
    "# example of the output during the run: https://gist.github.com/nevencaplar/bba8b38307ad4f8ef39ea43b3eef7229"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7173eeaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
